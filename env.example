# LLM World Generation Configuration
# Copy this file to .env.local and fill in your actual API keys

# Choose your LLM provider: openai, claude, or local
LLM_PROVIDER=openai

# API Keys (only set the one you're using)
# Get your OpenAI API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Get your Claude API key from: https://console.anthropic.com/
CLAUDE_API_KEY=sk-ant-your-claude-api-key-here

# Model Configuration (optional - defaults provided)
OPENAI_MODEL=gpt-4o
CLAUDE_MODEL=claude-3-5-sonnet-20241022
LOCAL_MODEL=local-model

# Local LLM Configuration (if using local provider)
# Point to your local LLM server (e.g., Ollama, LM Studio, etc.)
LOCAL_LLM_BASE_URL=http://localhost:1234
LOCAL_LLM_API_KEY=optional-local-api-key

# Generation Settings (optional - defaults provided)
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4000

# World Saving Configuration
# Set to 'true' to enable automatic saving of generated worlds to public/assets/worlds/
# Set to 'false' to disable world saving (worlds will only exist in memory)
# IMPORTANT: For production, consider setting this to 'false' for security
ENABLE_WORLD_SAVING=true

# Security Configuration
# Rate limiting and session management
MAX_CONCURRENT_SESSIONS=50
SESSION_TIMEOUT_MS=1800000

# Content Security
MAX_DESCRIPTION_LENGTH=2000
ENABLE_CONTENT_MODERATION=true

# Environment-specific settings
NODE_ENV=development

# Instructions:
# 1. Copy this file to .env.local for development
# 2. Set LLM_PROVIDER to your preferred provider
# 3. Add your API key for the chosen provider
# 4. Adjust security settings as needed
# 5. For production deployment:
#    - Set NODE_ENV=production
#    - Consider ENABLE_WORLD_SAVING=false
#    - Use lower session limits for cost control
#    - Monitor API usage with billing alerts
# 6. Restart your development server (npm run dev)
# 7. The AI World Generator will be ready to use! 